{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple text classification using ```scikit-learn```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:12:39.290472Z",
     "iopub.status.busy": "2022-03-28T12:12:39.289514Z",
     "iopub.status.idle": "2022-03-28T12:12:40.122230Z",
     "shell.execute_reply": "2022-03-28T12:12:40.121210Z",
     "shell.execute_reply.started": "2022-03-28T12:12:39.290416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# system tools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# data munging tools\n",
    "import pandas as pd\n",
    "import utils.classifier_utils as clf\n",
    "\n",
    "# Machine learning stuff\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is already in a tabular format, so we're going to load it using ```pandas```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data = fake or real news\\\n",
    "text data ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:15:21.036862Z",
     "iopub.status.busy": "2022-03-28T12:15:21.036359Z",
     "iopub.status.idle": "2022-03-28T12:15:21.362233Z",
     "shell.execute_reply": "2022-03-28T12:15:21.361431Z",
     "shell.execute_reply.started": "2022-03-28T12:15:21.036815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = os.path.join(\"..\", \"..\", \"431868\", \"classification_data\", \"fake_or_real_news.csv\")\n",
    "\n",
    "data = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inspect data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:15:22.266915Z",
     "iopub.status.busy": "2022-03-28T12:15:22.266409Z",
     "iopub.status.idle": "2022-03-28T12:15:22.282353Z",
     "shell.execute_reply": "2022-03-28T12:15:22.281776Z",
     "shell.execute_reply.started": "2022-03-28T12:15:22.266869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9076</th>\n",
       "      <td>Sean Hannity SHREDS FBI Director James Comey f...</td>\n",
       "      <td>Sean Hannity SHREDS FBI Director James Comey f...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Super PACs Escalate Air War Ahead of Iowa Cauc...</td>\n",
       "      <td>A new set of super PAC advertisements released...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>Future Obamacare Costs Keep Falling</td>\n",
       "      <td>Nearly five years after President Barack Obama...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6917</th>\n",
       "      <td>7 Ways To Prepare For An Economic Crisis</td>\n",
       "      <td>Bill White November 7, 2016 7 Ways To Prepare ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Is Facebook to blame for making us more polari...</td>\n",
       "      <td>Critics have worried that the algorithm Facebo...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Why the death of GOP 'loyalty pledge' matters</td>\n",
       "      <td>Donald Trump, Ted Cruz, and John Kasich have a...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>If You Live HERE, Forget Christmas Lights – Th...</td>\n",
       "      <td>0 comments \\nPerhaps no country has been more ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>Trump And His Supporters Are Fighting A Rigged...</td>\n",
       "      <td>Trump And His Supporters Are Fighting A Rigged...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>US, Japan Push to Fortify Alliances Amid Threa...</td>\n",
       "      <td>Get short URL 0 0 0 0 US Deputy Secretary of D...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>After Kim Davis is jailed, marriage license is...</td>\n",
       "      <td>(CNN) With the clerk who had refused them in j...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "9076  Sean Hannity SHREDS FBI Director James Comey f...   \n",
       "1467  Super PACs Escalate Air War Ahead of Iowa Cauc...   \n",
       "2424                Future Obamacare Costs Keep Falling   \n",
       "6917           7 Ways To Prepare For An Economic Crisis   \n",
       "3085  Is Facebook to blame for making us more polari...   \n",
       "1041      Why the death of GOP 'loyalty pledge' matters   \n",
       "7068  If You Live HERE, Forget Christmas Lights – Th...   \n",
       "9104  Trump And His Supporters Are Fighting A Rigged...   \n",
       "8996  US, Japan Push to Fortify Alliances Amid Threa...   \n",
       "2245  After Kim Davis is jailed, marriage license is...   \n",
       "\n",
       "                                                   text label  \n",
       "9076  Sean Hannity SHREDS FBI Director James Comey f...  FAKE  \n",
       "1467  A new set of super PAC advertisements released...  REAL  \n",
       "2424  Nearly five years after President Barack Obama...  REAL  \n",
       "6917  Bill White November 7, 2016 7 Ways To Prepare ...  FAKE  \n",
       "3085  Critics have worried that the algorithm Facebo...  REAL  \n",
       "1041  Donald Trump, Ted Cruz, and John Kasich have a...  REAL  \n",
       "7068  0 comments \\nPerhaps no country has been more ...  FAKE  \n",
       "9104  Trump And His Supporters Are Fighting A Rigged...  FAKE  \n",
       "8996  Get short URL 0 0 0 0 US Deputy Secretary of D...  FAKE  \n",
       "2245  (CNN) With the clerk who had refused them in j...  REAL  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:15:57.481869Z",
     "iopub.status.busy": "2022-03-28T12:15:57.481364Z",
     "iopub.status.idle": "2022-03-28T12:15:57.489668Z",
     "shell.execute_reply": "2022-03-28T12:15:57.488936Z",
     "shell.execute_reply.started": "2022-03-28T12:15:57.481821Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Q: How many examples of each label do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:17:06.618265Z",
     "iopub.status.busy": "2022-03-28T12:17:06.617774Z",
     "iopub.status.idle": "2022-03-28T12:17:06.630197Z",
     "shell.execute_reply": "2022-03-28T12:17:06.629165Z",
     "shell.execute_reply.started": "2022-03-28T12:17:06.618219Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's now create new variables called ```X``` and ```y```, taking the data out of the dataframe so that we can mess around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:20:59.125409Z",
     "iopub.status.busy": "2022-03-28T12:20:59.124923Z",
     "iopub.status.idle": "2022-03-28T12:20:59.131919Z",
     "shell.execute_reply": "2022-03-28T12:20:59.130910Z",
     "shell.execute_reply.started": "2022-03-28T12:20:59.125362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've included most of the 'hard work' for you here already, because these are long cells which might be easy to mess up while live-coding.\n",
    "\n",
    "Instead, we'll discuss what's happening. If you have questions, don't be shy!\n",
    "*every time we rund this function we* \n",
    "First value of X_train correspond to first section og y_train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T12:36:32.795905Z",
     "iopub.status.busy": "2022-03-28T12:36:32.795208Z",
     "iopub.status.idle": "2022-03-28T12:36:32.806564Z",
     "shell.execute_reply": "2022-03-28T12:36:32.805223Z",
     "shell.execute_reply.started": "2022-03-28T12:36:32.795854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,           # texts for the model\n",
    "                                                    y,          # classification labels\n",
    "                                                    test_size=0.2,   # create an 80/20 split\n",
    "                                                    random_state=42) # random state for reproducibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization. What is it and why are all the cool kids talking about it?\n",
    "\n",
    "Essentially, vectorization is the process whereby textual or visual data is 'transformed' into some kind of numerical representation. One of the easiest ways to do this is to simple count how often individual features appear in a document.\n",
    "\n",
    "Take the following text: \n",
    "<br><br>\n",
    "<i>My father’s family name being Pirrip, and my Christian name Philip, my infant tongue could make of both names nothing longer or more explicit than Pip. So, I called myself Pip, and came to be called Pip.</i>\n",
    "<br>\n",
    "\n",
    "We can convert this into the following vector\n",
    "\n",
    "| and | be | being | both | called | came | christian | could | explicit | family | father | i | infant | longer | make | more | my | myself | name | names | nothing | of | or | philip | pip | pirrip | s | so | than | to | tongue|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |  --- |\n",
    "| 2 | 1 | 1 | 1 | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 2 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 1 | 1 | 1 | 1 | 1 |\n",
    "\n",
    "<br>\n",
    "Our textual data is hence reduced to a jumbled-up 'vector' of numbers, known somewhat quaintly as a <i>bag-of-words</i>.\n",
    "<br>\n",
    "<br>\n",
    "To do this in practice, we first need to create a vectorizer. \n",
    "\n",
    "Tfidf vectors tend to be better for training classifiers. Why might that be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectorizer object\n",
    "  **defining a range of vectorizers that we want to work with**\\\n",
    "  the larger the ngrams, the more computational force it take. Could make threegrams or fourggrams instead of unigrams\\\n",
    "removing common/frequent word = stopwordlist *can't tell us anything, no strong prediction*\\\n",
    "removing rare words, *if we have words that only occur once, might be spelling mistakes or very rare concepts, just extreme outliers*\\\n",
    "removing top and bottom 5% \\\n",
    "computer thinks it can really trust that this  because it's true 100% of the time\\\n",
    "task-specific: \n",
    "cultural dataobjects, what are we doing why are we doing it and what is necessary for this specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:17.502500Z",
     "iopub.status.busy": "2022-03-28T13:17:17.502011Z",
     "iopub.status.idle": "2022-03-28T13:17:17.570253Z",
     "shell.execute_reply": "2022-03-28T13:17:17.569510Z",
     "shell.execute_reply.started": "2022-03-28T13:17:17.502455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2),     # make into unigrams and bigrams (1 word and 2 word units)\n",
    "                             lowercase =  True,       # why use lowercase?\n",
    "                             max_df = 0.95,           # remove very common words\n",
    "                             min_df = 0.05,           # remove very rare words\n",
    "                             max_features = 100)      # keep only top 100 features, makin a 100 words vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vectorizer is then used to turn all of our documents into a vector of numbers, instead of text.\\\n",
    "use my vectoriser on my training data\\\n",
    "fit the data to the model\\\n",
    "transform it to unigram and bigrams\\\n",
    "use same vectoriser to test data, vocabulary we used to make prediction, should be the same we're using for our test data\\\n",
    "do NOT fit the vectoriser to fit the test data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:23.170332Z",
     "iopub.status.busy": "2022-03-28T13:17:23.169719Z",
     "iopub.status.idle": "2022-03-28T13:17:26.600365Z",
     "shell.execute_reply": "2022-03-28T13:17:26.599006Z",
     "shell.execute_reply.started": "2022-03-28T13:17:23.170284Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first we fit to the training data... \n",
    "X_train_feats = vectorizer.fit_transform(X_train)\n",
    "\n",
    "#... then do it for our test data\n",
    "X_test_feats = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['about', 'after', 'all', 'also', 'an', 'and', 'and the', 'are',\n",
       "       'as', 'at', 'at the', 'be', 'because', 'been', 'but', 'by',\n",
       "       'campaign', 'can', 'clinton', 'could', 'do', 'even', 'first',\n",
       "       'for', 'for the', 'from', 'had', 'has', 'have', 'he', 'her',\n",
       "       'hillary', 'him', 'his', 'how', 'if', 'in', 'in the', 'into', 'is',\n",
       "       'it', 'its', 'just', 'like', 'many', 'more', 'most', 'new', 'no',\n",
       "       'not', 'now', 'obama', 'of', 'of the', 'on', 'on the', 'one',\n",
       "       'only', 'or', 'other', 'our', 'out', 'over', 'party', 'people',\n",
       "       'president', 'republican', 'said', 'she', 'so', 'some', 'state',\n",
       "       'states', 'than', 'that', 'that the', 'their', 'them', 'there',\n",
       "       'they', 'this', 'time', 'to be', 'to the', 'trump', 'two', 'up',\n",
       "       'us', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will',\n",
       "       'with', 'with the', 'would', 'you'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to 'fit' the classifier to our data.\n",
    "\n",
    "This means that the classifier takes our data and finds correlations between features and labels.\n",
    "\n",
    "These correlations are then the *model* that the classifier learns about our data. This model can then be used to predict the label for new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:31.431697Z",
     "iopub.status.busy": "2022-03-28T13:17:31.431195Z",
     "iopub.status.idle": "2022-03-28T13:17:31.466813Z",
     "shell.execute_reply": "2022-03-28T13:17:31.466126Z",
     "shell.execute_reply.started": "2022-03-28T13:17:31.431650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# heres my input and output I want you to fit it to the training dataset and by taht train the model\n",
    "classifier = LogisticRegression(random_state=42).fit(X_train_feats, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do we use the classifier to make predictions?\\\n",
    " by training it on the training dataset, and use that to make predicitions about the real text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:32.957309Z",
     "iopub.status.busy": "2022-03-28T13:17:32.956823Z",
     "iopub.status.idle": "2022-03-28T13:17:32.963699Z",
     "shell.execute_reply": "2022-03-28T13:17:32.962708Z",
     "shell.execute_reply.started": "2022-03-28T13:17:32.957263Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are the predictions for the first 20 examples of the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:35.051012Z",
     "iopub.status.busy": "2022-03-28T13:17:35.050490Z",
     "iopub.status.idle": "2022-03-28T13:17:35.058906Z",
     "shell.execute_reply": "2022-03-28T13:17:35.057898Z",
     "shell.execute_reply.started": "2022-03-28T13:17:35.050957Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAKE' 'FAKE' 'FAKE' 'FAKE' 'FAKE' 'FAKE' 'REAL' 'FAKE' 'REAL' 'FAKE'\n",
      " 'FAKE' 'REAL' 'REAL' 'FAKE' 'FAKE' 'FAKE' 'FAKE' 'REAL' 'REAL' 'REAL']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the model, in order to see which features are most informative when trying to predict a label. \n",
    "\n",
    "To do this, we can use the ```show_features``` function that I defined earlier - how convenient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are the most informative features? Use ```show_features```to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:17:38.051311Z",
     "iopub.status.busy": "2022-03-28T13:17:38.050711Z",
     "iopub.status.idle": "2022-03-28T13:17:38.061557Z",
     "shell.execute_reply": "2022-03-28T13:17:38.060803Z",
     "shell.execute_reply.started": "2022-03-28T13:17:38.051262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE\t\t\t\tREAL\n",
      "\n",
      "-0.2027\tjust           \t\t0.3138\tbut            \n",
      "-0.1674\tby             \t\t0.2158\tsaid           \n",
      "-0.1255\tthat the       \t\t0.1835\tstate          \n",
      "-0.1192\tus             \t\t0.1717\tthan           \n",
      "-0.1078\tbe             \t\t0.1492\twho            \n",
      "-0.0968\tthis           \t\t0.1446\tmost           \n",
      "-0.0906\twith           \t\t0.1258\tobama          \n",
      "-0.0878\thad            \t\t0.1145\tother          \n",
      "-0.0820\tyou            \t\t0.1073\tmore           \n",
      "-0.0690\tso             \t\t0.1019\tup             \n",
      "-0.0670\tto the         \t\t0.0988\ton the         \n",
      "-0.0668\tall            \t\t0.0953\talso           \n",
      "-0.0626\tis             \t\t0.0834\tpresident      \n",
      "-0.0616\tof the         \t\t0.0723\tone            \n",
      "-0.0614\tinto           \t\t0.0693\tshe            \n",
      "-0.0612\tthere          \t\t0.0693\ttwo            \n",
      "-0.0560\twas            \t\t0.0652\tthat           \n",
      "-0.0550\tlike           \t\t0.0647\tout            \n",
      "-0.0548\tnow            \t\t0.0544\tto be          \n"
     ]
    }
   ],
   "source": [
    "# even though we took away the most common words, there are still quite a lot of grammatical words\n",
    "# still don't know how well the model is actually working\n",
    "clf.show_features(vectorizer, y_train, classifier, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do some quick calculations, in order to assess just how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:18:02.772412Z",
     "iopub.status.busy": "2022-03-28T13:18:02.771808Z",
     "iopub.status.idle": "2022-03-28T13:18:02.862766Z",
     "shell.execute_reply": "2022-03-28T13:18:02.862174Z",
     "shell.execute_reply.started": "2022-03-28T13:18:02.772365Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_estimator(classifier,           # the classifier name\n",
    "                                            X_train_feats,          # the training features\n",
    "                                            y_train,                # the training labels\n",
    "                                            cmap=plt.cm.Blues,      # make the colours prettier\n",
    "                                            labels=[\"FAKE\", \"REAL\"])# the labels in your data arranged alphabetically"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix can be broken down a little bit more and used to draw more meaningful statistical results:\n",
    "\n",
    "<img src=\"../img/confusionMatrix.jpg\" alt=\"Alternative text\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating metrics__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```scikit-learn``` has a built-in set of tools which can be used to calculate these metrics, to get a better idea of how our model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:18:22.267289Z",
     "iopub.status.busy": "2022-03-28T13:18:22.266672Z",
     "iopub.status.idle": "2022-03-28T13:18:22.292665Z",
     "shell.execute_reply": "2022-03-28T13:18:22.292035Z",
     "shell.execute_reply.started": "2022-03-28T13:18:22.267241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_metrics = metrics.classification_report(y_test, y_pred)\n",
    "print(classifier_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross validation and further evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can't be sure of is that our model performance is simply related to how the train-test split is made.\n",
    "\n",
    "To try to mitigate this, we can perform cross-validation, in order to test a number of different train-test splits and finding the average scores.\n",
    "\n",
    "Let's do this on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:18:32.563006Z",
     "iopub.status.busy": "2022-03-28T13:18:32.562497Z",
     "iopub.status.idle": "2022-03-28T13:18:36.378503Z",
     "shell.execute_reply": "2022-03-28T13:18:36.377522Z",
     "shell.execute_reply.started": "2022-03-28T13:18:32.562958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot is probably the most interesting. Some terminology:\n",
    "\n",
    "- If two curves are \"close to each other\" and both of them but have a low score, the model suffers from an underfitting problem (High Bias)\n",
    "\n",
    "- If there are large gaps between two curves, then the model suffer from an overfitting problem (High Variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:18:42.181255Z",
     "iopub.status.busy": "2022-03-28T13:18:42.180757Z",
     "iopub.status.idle": "2022-03-28T13:18:45.510822Z",
     "shell.execute_reply": "2022-03-28T13:18:45.510110Z",
     "shell.execute_reply.started": "2022-03-28T13:18:42.181208Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LogisticRegression(random_state=42)\n",
    "clf.plot_learning_curve(estimator, title, X_vect, y, cv=cv, n_jobs=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second plot shows how model performance scales when more data is added;\n",
    "- The third plot shows how much of a performance improvement we get from adding more data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models\n",
    "\n",
    "It is also somewhat trivial to save models and reload them for later use. For that, we can use the library ```joblib```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:23:43.082858Z",
     "iopub.status.busy": "2022-03-28T13:23:43.082337Z",
     "iopub.status.idle": "2022-03-28T13:23:43.093599Z",
     "shell.execute_reply": "2022-03-28T13:23:43.092722Z",
     "shell.execute_reply.started": "2022-03-28T13:23:43.082808Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(classifier, \"LR_classifier.joblib\")\n",
    "dump(vectorizer, \"tfidf_vectorizer.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can restart the kernel for our notebook to see how that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:24:43.930596Z",
     "iopub.status.busy": "2022-03-28T13:24:43.930071Z",
     "iopub.status.idle": "2022-03-28T13:24:43.939338Z",
     "shell.execute_reply": "2022-03-28T13:24:43.938266Z",
     "shell.execute_reply.started": "2022-03-28T13:24:43.930532Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "loaded_clf = load(\"LR_classifier.joblib\")\n",
    "loaded_vect = load(\"tfidf_vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:25:28.017733Z",
     "iopub.status.busy": "2022-03-28T13:25:28.017226Z",
     "iopub.status.idle": "2022-03-28T13:25:28.023554Z",
     "shell.execute_reply": "2022-03-28T13:25:28.022552Z",
     "shell.execute_reply.started": "2022-03-28T13:25:28.017686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"Hilary Clinton is a crook who eats babies!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-28T13:27:18.798236Z",
     "iopub.status.busy": "2022-03-28T13:27:18.797749Z",
     "iopub.status.idle": "2022-03-28T13:27:18.810310Z",
     "shell.execute_reply": "2022-03-28T13:27:18.807453Z",
     "shell.execute_reply.started": "2022-03-28T13:27:18.798190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sentence = loaded_vect.transform([sentence])\n",
    "loaded_clf.predict(test_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Interpreting a confusion matrix\n",
    "\n",
    "Imagine that we are testing a classifier to see how well it can predict if someone has COVID:\n",
    "\n",
    "\n",
    "```Accuracy => (TP+TN)/(TP+FP+FN+TN)```\n",
    "- Ratio of correct classifications across all of the patients\n",
    "\n",
    "```True Positive Rate => Recall  => Sensitivity => (TP / TP + FN)```\n",
    "- The proportion of the positive class who were correctly classified\n",
    "    - I.e sick people correctly identified as being sick\n",
    "\n",
    "```Precision =>  (TP / TP + FP)```\n",
    "- The ration of true positives to everyone predicted as positive\n",
    "    - I.e. the proportion we identify as having COVID who actually do have it\n",
    "\n",
    "```True negative rate => Specificity => (TN / TN + FP)```\n",
    "- The proportion of the negative class who were correctly classified\n",
    "    - I.e. healthy people who were correctly identified as being healthy\n",
    "\n",
    "The following can also be calculated but are not featured on the confusion matrix above:\n",
    "\n",
    "```False negative rate => (FN / TP + FN)```\n",
    "- Proportion of the positive class who were incorrectly classified by the classifier\n",
    "  - I.e. people predicted as healthy who are actually sick\n",
    "\n",
    "```False positive rate = (FP / TN + FP) = 1 - Specificity```\n",
    "- Proportion of the negative class who were incorrectly classified by the classifier\n",
    "  - I.e. people predicted as sick who are actually healthy\n",
    "\n",
    "```F1 => 2(P*R / P + R)```\n",
    "- Harmonic mean of precision and recall, useful where both precision and recall are important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
